## HDFS
- Kiến trúc của HDFS
	+ HDFS Namenode
	+ HDFS Datanode
- Vai trò của Namenode và Datanode: 
	+ NameNode đóng vai trò là bộ não trung tâm điều phối toàn bộ hệ thống tệp tin phân tán bằng cách **quản lý không gian tên và siêu dữ liệu (metadata)**. Thực thể này lưu trữ danh sách các tệp tin cùng các thuộc tính quan trọng như ngày tạo và hệ số nhân bản, đồng thời thiết lập **sơ đồ ánh xạ từ tên tệp tới các chunk dữ liệu và vị trí của chúng trên các DataNode** . Để đảm bảo tốc độ truy xuất cực nhanh, toàn bộ **siêu dữ liệu thường được lưu trữ trực tiếp trong bộ nhớ trong (RAM)**. Ngoài nhiệm vụ **quản lý cấu hình cụm máy chủ**, NameNode còn chịu trách nhiệm **duy trì nhật ký các thao tác** như tạo hay xóa tệp và thực thi các cơ chế **nhân bản hoặc tái nhân bản** để đảm bảo tính toàn vẹn của dữ liệu trong hệ thống.

	+ Trong khi đó, DataNode đóng vai trò là các máy chủ lưu trữ vật lý, trực tiếp lưu giữ dữ liệu trên hệ thống tệp tin cục bộ và quản lý các **siêu dữ liệu đi kèm như mã kiểm tra lỗi CRC** để đảm bảo tính chính xác khi phục vụ dữ liệu cho máy khách. Để NameNode có cái nhìn tổng quát về hệ thống, các **DataNode định kỳ gửi báo cáo lưu trữ (Block Report)** liệt kê tất cả các chunk đang nắm giữ và **duy trì tín hiệu "nhịp đập" (heartbeat) sau mỗi 3 giây** nhằm xác nhận trạng thái hoạt động. Bên cạnh đó, DataNode còn **hỗ trợ khả năng trung chuyển dữ liệu dạng đường ống (pipelining)**, cho phép chuyển tiếp dữ liệu tới các node phù hợp khác trong cụm, giúp quá trình ghi dữ liệu diễn ra liên tục và hiệu quả.

- Nhân bản dữ liệu: 
	+ Chiến lược **Chunk Replacement** trong HDFS là cơ chế then chốt để đảm bảo tính sẵn sàng cao bằng cách phân bổ các bản sao dữ liệu một cách thông minh qua các **Rack** (tủ rack) — đơn vị vật lý chứa một nhóm các máy chủ chia sẻ chung một bộ chuyển mạch mạng (switch). Để tối ưu hóa việc chịu lỗi, HDFS không bao giờ đặt tất cả bản sao trong cùng một rack nhằm tránh kịch bản mất trắng dữ liệu khi rack đó gặp sự cố về điện hoặc mạng; cụ thể, hệ thống sẽ đặt **bản sao đầu tiên trên máy chủ đích** (thường là node gần client nhất), **bản sao thứ hai tại một tủ rack khác**, và **bản sao thứ ba nằm cùng tủ rack với bản sao thứ hai** nhưng trên một node khác. Quy tắc này giúp cân bằng giữa hiệu quả truyền thông nội bộ rack và khả năng phục hồi dữ liệu, đồng thời cho phép **Client đọc từ nhân bản gần nó nhất** để giảm thiểu độ trễ mạng, trong khi các bản sao bổ sung sau đó có thể được đặt tại các vị trí ngẫu nhiên để tối ưu hóa tải trọng toàn hệ thống.
	+ Khi NameNode phát hiện một DataNode gặp sự cố không thể truy xuất thông qua việc mất tín hiệu heartbeat, nó sẽ tự động kích hoạt quy trình tái nhân bản để duy trì hệ số an toàn cho dữ liệu. Trong quá trình này, NameNode sẽ **chọn một DataNode mới** để tiến hành nhân bản các chunk dữ liệu bị thiếu từ các bản sao còn lại trong cụm. Việc lựa chọn node mới không diễn ra ngẫu nhiên mà dựa trên các thuật toán tối ưu nhằm **cân bằng không gian lưu trữ** (Disk Utilization) giữa các máy chủ, tránh tình trạng node quá đầy hoặc quá trống, đồng thời **cân bằng số lượng kết nối** (Network Traffic) để ngăn chặn việc một DataNode bị quá tải khi có quá nhiều máy khách truy cập cùng lúc.
- Tái nhân bản dữ liệu:
	+ Quá trình **Tái nhân bản dữ liệu** (Rebalancing) trong HDFS tập trung vào mục tiêu duy trì **tỉ lệ phần trăm lấp đầy ổ cứng đồng đều** giữa các DataNode, giúp tối ưu hóa hiệu suất đọc/ghi toàn hệ thống và tránh tình trạng "node nóng" (hotspot). Hoạt động này thường được kích hoạt khi **có một node mới tham gia vào cụm** để san sẻ tải trọng từ các node cũ đã đầy, hoặc khi có sự chênh lệch lớn về dung lượng giữa các máy chủ. Một đặc điểm quan trọng là trong suốt quá trình di chuyển các block dữ liệu, **cụm vẫn hoạt động bình thường** mà không gây gián đoạn dịch vụ cho người dùng. Để đảm bảo tính ổn định, quá trình tái nhân bản có thể được cấu hình **điều chỉnh băng thông (threshold)** nhằm tránh gây tắc nghẽn mạng nội bộ, và quản trị viên có thể chủ động **sử dụng công cụ dòng lệnh** để kích hoạt và kiểm soát tiến trình này theo nhu cầu thực tế.
- Đảm bảo tính đúng đắn của dữ liệu:
	+ Để **đảm bảo tính đúng đắn của dữ liệu**, HDFS sử dụng cơ chế **checksum** (mã kiểm tra lỗi) dựa trên thuật toán **CRC 32** nhằm phát hiện các hư hỏng dữ liệu có thể xảy ra trong quá trình truyền tải hoặc lưu trữ trên đĩa cứng. **Tại thời điểm khởi tạo** (khi ghi dữ liệu), **Client sẽ tính toán checksum cho mỗi 512 bytes** và gửi kèm dữ liệu đến DataNode để các giá trị checksum này được lưu trữ lại một cách hệ thống. **Tại thời điểm truy cập** (khi đọc dữ liệu), **Client nhận về cả dữ liệu và checksum tương ứng từ DataNode** để thực hiện tính toán đối chiếu lại ngay lập tức; **nếu quá trình xác nhận dữ liệu không đạt** (checksum không khớp), hệ thống sẽ coi bản sao đó đã bị lỗi và Client sẽ tự động chuyển sang **thử lấy dữ liệu từ các nhân bản khác** để đảm bảo tính toàn vẹn thông tin.
- Data pipelining: 
	+ Cơ chế **Data Pipelining** (Đường ống dữ liệu) là phương thức HDFS tối ưu hóa băng thông mạng khi ghi các bản sao của một khối dữ liệu. Sau khi nhận được danh sách các DataNode từ NameNode để đặt bản sao, thay vì gửi dữ liệu song song đến tất cả các máy chủ (gây quá tải băng thông tại máy khách), **Client chỉ ghi khối dữ liệu vào DataNode đầu tiên** trong danh sách. Ngay lập tức, **DataNode đầu tiên này sẽ chuyển tiếp dữ liệu sang node kế tiếp** trong đường ống, và quá trình tiếp tục cho đến khi bản sao cuối cùng được hình thành. Chỉ **khi tất cả các bản sao đã được ghi xong** và xác nhận thành công, **Client mới chuyển sang ghi khối dữ liệu tiếp theo** của tệp tin, giúp tận dụng tối đa băng thông song song giữa các node trong cụm và giảm thiểu áp lực truyền tải trực tiếp từ phía máy khách.
- Secondary Namenode: 
	+ Trong kiến trúc HDFS, vì **NameNode** đóng vai trò là điểm lỗi duy nhất (**Single Point of Failure**), **Secondary NameNode** được triển khai để thực hiện cơ chế **Checkpointing** nhằm duy trì bản sao mới nhất của hệ thống tệp tin. Quá trình này bắt đầu bằng việc Secondary NameNode **sao chép file FsImage và các file nhật ký giao dịch (Transaction Log/EditLog) từ NameNode** chính về một thư mục tạm thời của nó. Tại đây, Secondary NameNode tiến hành **hợp nhất FsImage và Transaction Log thành một file FsImage mới** có nội dung cập nhật, sau đó **tải file FsImage mới này lên lại NameNode** chính. Ngay khi quá trình tải lên hoàn tất, **Transaction Log trên NameNode chính sẽ được xóa bỏ** (purged) để bắt đầu một chu kỳ ghi nhật ký mới, giúp NameNode tránh được tình trạng file log quá lớn và rút ngắn đáng kể thời gian phục hồi mỗi khi hệ thống khởi động lại.
- Làm sao để đạt được HA cho namenode?
	+ Để đạt được tính sẵn sàng cao (**High Availability - HA**) cho NameNode và loại bỏ điểm lỗi duy nhất, hệ thống triển khai cặp **Active NameNode** và **Standby NameNode** hoạt động song song. Trong kiến trúc này, Active NameNode là node duy nhất trực tiếp xử lý các yêu cầu từ phía client, trong khi Standby NameNode duy trì trạng thái dữ liệu giống hệt Active để sẵn sàng thay thế ngay lập tức nếu sự cố xảy ra. Để giải quyết bài toán đồng bộ dữ liệu thời gian thực, hệ thống sử dụng một nhóm các **Journal Nodes** (thường là 3 node để đảm bảo cơ chế biểu quyết đa số); khi Active NameNode phát sinh các giao dịch mới, nó sẽ ghi **Transaction Log** vào các Journal Nodes này, và Standby NameNode sẽ liên tục đọc log từ đó để cập nhật trạng thái metadata của mình. Việc phát hiện sự cố và chuyển đổi vai trò được thực hiện tự động thông qua dịch vụ **Zookeeper** và thành phần **FailoverController** (ZKFC) chạy trên mỗi NameNode; ZKFC duy trì một kết nối ổn định với Zookeeper, nếu Active NameNode bị chết hoặc mất kết nối, Zookeeper sẽ nhận diện và phối hợp với FailoverController để bầu chọn Standby Node lên làm Active một cách nhanh chóng và minh bạch.

## HDFS data format: 
	+ Hệ thống HDFS hỗ trợ đa dạng định dạng lưu trữ nhằm tối ưu hóa cho các mục đích sử dụng khác nhau, từ giai đoạn phát triển ban đầu đến các hệ thống sản xuất quy mô lớn. **Text file** (như CSV, JSON) là định dạng phổ biến nhất nhờ khả năng dễ đọc và trao đổi giữa các ứng dụng, tuy nhiên chúng không hỗ trợ nén khối và truy vấn kém hiệu quả, chỉ phù hợp cho giai đoạn thử nghiệm. Để khắc phục, **Sequence file** cung cấp cấu trúc dữ liệu bền vững cho các cặp binary key-value, cho phép nén, phân tách dữ liệu (splittable) ngay cả khi đã nén, và thường được dùng để đóng gói các tệp nhỏ hoặc chuyển tiếp dữ liệu giữa các MapReduce job. Trong nhóm các định dạng hiện đại, **Avro** là định dạng lưu trữ dạng dòng (row-based) mạnh mẽ với schema được nhúng trực tiếp dưới dạng JSON, hỗ trợ nhiều kiểu dữ liệu phức tạp và có khả năng phát hiện hư hỏng dữ liệu, cực kỳ linh hoạt cho các hệ thống cần thay đổi schema thường xuyên. Ngược lại, **Parquet** và **ORC** là các định dạng hướng cột (column-oriented) tối ưu cho hiệu năng đọc/ghi và các truy vấn phân tích sâu. **Parquet** nổi bật với khả năng nén trang, phân tách dữ liệu và hỗ trợ các cột lồng nhau (nested columns). Trong khi đó, **ORC (Optimized Row Columnar)** tiến xa hơn bằng cách nén riêng biệt từng cột trong các nhóm dòng, tích hợp chỉ mục nhẹ giúp bỏ qua các khối dữ liệu không liên quan và lưu trữ các giá trị tổng hợp (min, max, sum) ở cấp độ cột, giúp tăng tốc độ xử lý song song và tối ưu hóa tài nguyên đĩa một cách triệt để.