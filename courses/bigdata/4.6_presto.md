# Giải thích chi tiết về Presto

## 1. Motivation - Lý do ra đời dựa trên Hive và HDFS

### Vấn đề với Hive và MapReduce truyền thống:

**Hive + MapReduce có những hạn chế:**
- **Quá chậm cho truy vấn tương tác**: Mỗi query phải chạy qua các MapReduce jobs, mất từ vài phút đến vài giờ
- **Disk I/O bottleneck**: MapReduce ghi dữ liệu trung gian ra disk giữa các stage, gây chậm trễ lớn
- **Không phù hợp cho Ad-hoc queries**: Người dùng muốn khám phá dữ liệu nhanh chóng, không thể chờ hàng phút/giờ
- **Thiếu khả năng tương tác**: Không hỗ trợ tốt các công cụ BI (Business Intelligence) thương mại

**HDFS vẫn có giá trị:**
- Lưu trữ dữ liệu phân tán, có khả năng mở rộng tốt
- Đã có sẵn tại Facebook và nhiều công ty lớn
- Chứa lượng dữ liệu khổng lồ cần phân tích

**→ Động lực tạo ra Presto:**
- Cần một công cụ **truy vấn nhanh** trên dữ liệu HDFS/Hive hiện có
- Giữ lại **ANSI SQL interface** quen thuộc
- **In-memory processing** thay vì disk I/O
- Hỗ trợ **multiple data sources**, không chỉ Hive

---

## 2. What can Presto do? - Presto có thể làm gì?

### Các tính năng chính:

1. **Open-source distributed SQL query engine**
   - Chạy production tại Facebook từ 2013
   - Cộng đồng mạnh, được nhiều công ty lớn sử dụng

2. **ANSI SQL interface**
   - Cú pháp SQL chuẩn, dễ học
   - Không cần học ngôn ngữ mới như Pig, Cascading

3. **Interactive queries (milli-seconds to minutes)**
   - Truy vấn nhanh: từ vài ms đến vài phút
   - Phù hợp cho khám phá dữ liệu, phân tích ad-hoc

4. **Bổ sung, không thay thế MapReduce/Hive**
   - MapReduce/Hive vẫn cần cho **ETL (Extract-Transform-Load)**
   - Presto dùng cho truy vấn phân tích nhanh

5. **BI Tools Integration**
   - ODBC/JDBC drivers đáng tin cậy
   - Kết nối với Tableau, Power BI, etc.

6. **Query across multiple data sources**
   - Hive, HBase, Cassandra, MySQL, PostgreSQL, etc.
   - **Federated queries**: JOIN dữ liệu từ nhiều nguồn khác nhau

7. **Plugin mechanism**
   - Connector plugins cho các data sources
   - Mở rộng dễ dàng

8. **Unified analytics platform**
   - Tích hợp batch analysis + visualization
   - Một nền tảng cho nhiều use cases

---

## 3. Presto Architecture - Kiến trúc Presto

### Các thành phần chính:

```
┌─────────────────────────────────────────────────────┐
│                 Discovery Service                   │
│         (Tìm các servers trong cluster)             │
└─────────────────────────────────────────────────────┘
                         │
        ┌────────────────┼────────────────┐
        │                                 │
┌───────▼────────┐              ┌────────▼────────┐
│  Coordinator   │              │    Workers      │
│  - Parse SQL   │              │  - Execute      │
│  - Plan Query  │              │    tasks        │
│  - Schedule    │◄────────────►│  - Process      │
└────────┬───────┘              │    data         │
         │                      └────────┬────────┘
         │                               │
         ▼                               ▼
┌────────────────┐              ┌────────────────┐
│Connector Plugin│              │Connector Plugin│
│  - Metadata    │              │  - Read data   │
│  - Schema      │              │  - Splits      │
└────────────────┘              └────────────────┘
         │                               │
         ▼                               ▼
┌─────────────────────────────────────────────────┐
│           Storage (Hive/HDFS/Cassandra)        │
└─────────────────────────────────────────────────┘
```

### Chi tiết từng thành phần:

#### **Discovery Service**
- Quản lý danh sách các servers trong cluster
- Coordinator và Workers đăng ký với Discovery Service
- Giúp các thành phần tìm thấy nhau

#### **Coordinator**
- **Brain của Presto cluster**
- Nhiệm vụ:
  - Parse SQL query
  - Build query plan (kế hoạch thực thi)
  - Schedule tasks cho workers
  - Coordinate execution (điều phối)
- Sử dụng **Connector Plugin** để lấy metadata (schema, partitions, etc.)

#### **Workers**
- **Hands của Presto cluster**
- Nhiệm vụ:
  - Nhận tasks từ Coordinator
  - Đọc dữ liệu qua Connector Plugin
  - Xử lý dữ liệu **in-memory**
  - Trả kết quả cho Client hoặc Workers khác

#### **Connector Plugin**
- **Interface giữa Presto và Storage**
- Cung cấp:
  - **Metadata**: table schema, partition info
  - **Data access**: đọc dữ liệu từ storage
  - **Splits**: phân chia dữ liệu thành chunks nhỏ
- Viết bằng Java, có thể custom

---

## 4. Query Execution Flow - Luồng thực thi truy vấn

### **Bước 1: Discovery Service finds servers**
- Client hoặc các thành phần mới join cluster
- Discovery Service cung cấp danh sách Coordinator và Workers

### **Bước 2: Client sends query (HTTP)**
```
Client ──[HTTP + JSON]──> Coordinator
         "SELECT * FROM orders WHERE country='VN'"
```
- Client gửi SQL query qua HTTP
- Format: HTTP POST với JSON payload

### **Bước 3: Coordinator builds query plan**
```
Coordinator:
  1. SQL Parser: Parse SQL thành AST (Abstract Syntax Tree)
  2. Analyzer: Validate + resolve tables/columns
  3. Logical Planner: Tạo logical plan
  4. Optimizer: Optimize plan
  5. Physical Planner: Tạo distributed execution plan
  
Connector Plugin cung cấp:
  - Table schema (cột nào có, kiểu dữ liệu gì)
  - Partition info (dữ liệu chia như thế nào)
  - Statistics (để optimize)
```

**Query Plan Structure:**
- Chia thành **Stages** (giai đoạn thực thi)
- Mỗi Stage có nhiều **Tasks** (chạy song song)
- Mỗi Task xử lý nhiều **Splits** (chunks của data)

### **Bước 4: Coordinator sends tasks to workers**
```
Coordinator:
  - Schedule tasks dựa trên data locality
  - Assign splits cho từng task
  - Gửi task details cho Workers via HTTP

Worker 1: Task 1.0 (process Split 1, 2, 3)
Worker 2: Task 1.1 (process Split 4, 5, 6)
Worker 3: Task 1.2 (process Split 7, 8, 9)
```

### **Bước 5: Workers read data through connector plugin**
```
Worker:
  1. Nhận task từ Coordinator
  2. Dùng Connector Plugin để đọc splits
  3. Connector đọc data từ HDFS/Hive/Cassandra
  
Ví dụ Hive Connector:
  - Split = HDFS file path + offset + length
  - Đọc ORC/Parquet file từ HDFS
  - Deserialize thành rows
```

### **Bước 6: Workers run tasks - IN MEMORY**
```
Worker memory processing:
  - Filter rows (WHERE clause)
  - Project columns (SELECT clause)
  - Join với data từ workers khác
  - Aggregate (GROUP BY, SUM, COUNT)
  - Sort (ORDER BY)
  
⚠️ Quan trọng:
  - Tất cả xử lý trong RAM
  - Không ghi intermediate data ra disk
  - Pipeline processing: stage sau nhận data ngay từ stage trước
  - Nếu hết memory → query FAILS
```

### **Bước 7: Client gets result from worker**
```
Worker ──[HTTP + JSON]──> Client
         Streaming results page by page
         
- Client không đợi toàn bộ kết quả
- Nhận từng page (streaming)
- Format: JSON hoặc binary
```

---

## 5. Presto Connectors - Chi tiết

### **Connector là gì?**
- Plugin để Presto kết nối với data sources
- Written in Java
- Implements interface của Presto

### **Chức năng của Connector:**

#### **1. Metadata access**
```java
// Connector cung cấp cho Coordinator:
- listSchemas()
- listTables(schemaName)
- getTableMetadata(tableName)
  → Columns: name, type
  → Partition keys
  → Table properties
```

#### **2. Data access**
```java
// Connector cung cấp cho Workers:
- getSplits(table, constraint)
  → Trả về danh sách splits để đọc
  
- getRecordSet(split)
  → Đọc dữ liệu từ split
  → Trả về iterator of rows
```

### **Các Connector phổ biến:**

#### **Hive Connector**
- Đọc data từ Hive tables trên HDFS
- Hỗ trợ formats: ORC, Parquet, Avro, Text
- Đọc Hive Metastore để lấy schema
- Data locality: schedule tasks gần HDFS datanodes

#### **Cassandra Connector**
- Đọc từ Cassandra NoSQL database
- Push-down predicates để filter ở Cassandra
- Partition-aware scheduling

#### **MySQL/PostgreSQL (JDBC Connector)**
- Connect qua JDBC
- Có thể JOIN Hive data với MySQL data!
- Push-down WHERE, aggregations xuống DB

#### **Custom Connector**
- Bạn có thể viết connector riêng
- Ví dụ: connect đến REST API, Elasticsearch, etc.

---

## 6. Distributed Architecture - Kiến trúc phân tán

### **3 loại servers:**

**1. Discovery Service**
- Service registry
- Health checking
- Thường dùng 1 instance (hoặc HA setup)

**2. Coordinator**
- 1 coordinator per cluster (hoặc standby cho HA)
- Không xử lý dữ liệu, chỉ điều phối
- Cần nhiều memory cho planning

**3. Workers**
- Nhiều workers (10s, 100s, 1000s)
- Xử lý dữ liệu thực sự
- Càng nhiều workers → càng nhanh

### **Presto is NOT a database:**
- Không lưu trữ dữ liệu
- Chỉ cung cấp SQL interface cho data stores hiện có
- "SQL-on-Anything" engine

### **Client Protocol: HTTP + JSON**
- RESTful API
- Language bindings:
  - Ruby, Python, PHP: HTTP clients
  - Java: JDBC driver
  - R, Node.js: community drivers

---

## 7. Execution Model - Mô hình thực thi

### **Presto ≠ MapReduce**

#### **MapReduce:**
```
Map → [Write to disk] → Shuffle → [Write to disk] → Reduce
      ↑ slow                      ↑ slow
```

#### **Presto:**
```
Stage 1 → Stage 2 → Stage 3
  ↓         ↓         ↓
Memory → Memory → Memory (pipelined, no disk I/O)
```

### **DAG-based execution (như Apache Tez, MPP databases)**

**Query Plan → Stages → Tasks**

```
Query: SELECT country, COUNT(*) 
       FROM orders 
       GROUP BY country

DAG:
┌─────────────┐
│  Stage 3    │  Final Aggregation
│  (Single)   │
└──────▲──────┘
       │
┌──────┴──────┐
│  Stage 2    │  Partial Aggregation + Exchange
│ (Distributed)│
└──────▲──────┘
       │
┌──────┴──────┐
│  Stage 1    │  Table Scan
│  (Source)   │
└─────────────┘
```

### **Coordinator Workflow:**

#### **1. SQL Parser**
```sql
SELECT country, COUNT(*) FROM orders
↓
AST (Abstract Syntax Tree)
```

#### **2. Query Planner (Logical Plan)**
```
Project(country, count)
  └─ Aggregate(country, count(*))
       └─ TableScan(orders)
```

#### **3. Optimizer**
- Predicate pushdown
- Column pruning
- Join reordering
- Cost-based optimization

#### **4. Execution Planner (Physical Plan)**
- Chia thành Stages
- Xác định exchange points (shuffle data)
- Tạo Tasks cho mỗi Stage

### **Workers Workflow:**

#### **Task Execution Scheduler**
- Nhận tasks từ Coordinator
- Quản lý thread pools
- Execute operators pipeline
- Report progress về Coordinator

---

## 8. Query Planner & Execution Planner

### **Stages - Giai đoạn thực thi**

Một query được chia thành nhiều **Stages**:

```
┌──────────────────────────────────────┐
│         Stage 0 (Root)               │
│    Final aggregation/output          │
└────────────▲─────────────────────────┘
             │ Exchange (shuffle)
┌────────────┴─────────────────────────┐
│         Stage 1 (Intermediate)       │
│    Partial aggregation/join          │
└────────────▲─────────────────────────┘
             │ Exchange
┌────────────┴─────────────────────────┐
│         Stage 2, 3 (Source/Leaf)     │
│         Table scans                  │
└──────────────────────────────────────┘
```

**Loại Stages:**
- **Source/Leaf Stages**: Đọc từ connector (table scan)
- **Intermediate Stages**: Xử lý trung gian (joins, aggregations)
- **Root Stage**: Stage cuối, trả kết quả về client

### **Tasks - Đơn vị thực thi**

- Mỗi Stage có nhiều Tasks chạy **song song**
- Mỗi Task chạy trên 1 Worker
- Tasks xử lý **nhiều Splits**

```
Stage 1:
  Task 1.0 on Worker A
  Task 1.1 on Worker B
  Task 1.2 on Worker C
  ... (all run in parallel)
```

---

## 9. Scheduling - Lập lịch thực thi

### **Stage Scheduling - 2 chiến lược:**

#### **1. All-at-once Scheduling**
```
Time ──────────────────────────────>
Stage 1: ████████████
Stage 2:     ████████████
Stage 3:         ████████████

→ Tất cả stages chạy đồng thời ngay khi có dữ liệu
```

**Ưu điểm:**
- **Latency thấp**: Giảm tổng thời gian query
- Pipeline processing: Stage sau xử lý ngay data từ stage trước
- Phù hợp: Interactive analytics, A/B testing

**Nhược điểm:**
- Tốn nhiều memory cùng lúc

#### **2. Phased Scheduling**
```
Time ──────────────────────────────>
Stage 1: ████████████
Stage 2:             ████████████
Stage 3:                         ████████

→ Chờ stage trước hoàn thành mới chạy stage sau
```

**Ưu điểm:**
- **Memory efficiency**: Chỉ dùng memory cho 1 stage 1 lúc
- Phù hợp: Batch analytics với dữ liệu lớn

**Nhược điểm:**
- Chậm hơn all-at-once

### **Task Scheduling - Gán tasks cho workers**

#### **Leaf Stages (Source stages):**
```
Principle: Data Locality
→ Schedule tasks GẦN nơi lưu dữ liệu

Ví dụ Hive/HDFS:
  Split 1 on HDFS Node A → Schedule task to Worker A (co-located)
  Split 2 on HDFS Node B → Schedule task to Worker B
  
→ Giảm network transfer, tăng tốc độ
```

**Connector Data Layout Constraints:**
- Connector chỉ định splits phải chạy ở worker nào
- VD: Cassandra connector → tasks chạy trên Cassandra nodes

#### **Intermediate Stages:**
```
Không có ràng buộc data locality
→ Tasks có thể chạy trên BẤT KỲ worker nào
→ Scheduler cân bằng load
```

**Quyết định số lượng tasks:**
- Dựa trên:
  - Số lượng splits
  - Kích thước dữ liệu
  - Số workers available
  - Target parallelism

---

## 10. Split Scheduling - Lập lịch Splits

### **Split là gì?**

> **Split** = Opaque handle to an addressable chunk of data

**Trong HDFS:**
```
Split = {
  filePath: "/user/hive/warehouse/orders/part-00001.orc",
  offset: 67108864,      // 64MB
  length: 134217728      // 128MB
}
```

**Trong Cassandra:**
```
Split = {
  keyspace: "analytics",
  table: "events",
  tokenRange: [1000, 2000]
}
```

### **Split Assignment - Lazy Loading**

#### **Không enumerate tất cả splits trước:**
```
❌ BAD (upfront):
  Coordinator: "Lấy tất cả 10,000 splits từ Hive Metastore"
  → Tốn memory lưu metadata
  → Phải đợi lâu mới bắt đầu

✅ GOOD (lazy):
  Coordinator: "Lấy 100 splits đầu tiên"
  → Assign cho workers
  → Workers bắt đầu xử lý NGAY
  → Coordinator tiếp tục lấy thêm splits
```

**Lợi ích:**
1. **Fast query startup**: Không đợi enumerate hết
2. **Memory efficiency**: Không lưu tất cả split metadata
3. **Early termination**: Queries với LIMIT có thể dừng sớm

### **Split Assignment Strategy:**

```
Coordinator tracks:
  - Mỗi worker đang xử lý bao nhiêu splits (queue depth)
  
Assignment:
  newSplit → assign to worker with SHORTEST QUEUE
  
→ Load balancing tự động
```

---

## 11. Query Optimization

### **1. Data Layouts Optimization**

#### **Physical Properties của data:**
- **Partitioning**: Dữ liệu chia theo cột nào? (VD: partition by date)
- **Sorting**: Dữ liệu đã được sắp xếp chưa?
- **Grouping**: Dữ liệu đã được nhóm chưa?
- **Indexes**: Có index nào không?

#### **Optimizer sử dụng properties:**

**Ví dụ 1: Partition Elimination**
```sql
SELECT * FROM orders 
WHERE order_date = '2026-01-01'

Data layout: partitioned by order_date
→ Optimizer: Chỉ scan partition order_date=2026-01-01
→ Bỏ qua 99% dữ liệu!
```

**Ví dụ 2: Sorted Data**
```sql
SELECT * FROM orders 
ORDER BY order_id

Data layout: sorted by order_id
→ Optimizer: Bỏ qua sort operation
```

#### **Multiple Layouts:**
```
Table: orders
  Layout 1: Partitioned by date, sorted by customer_id
  Layout 2: Partitioned by country, sorted by order_id
  
Query 1: WHERE order_date='...' ORDER BY customer_id
→ Optimizer chọn Layout 1

Query 2: WHERE country='VN' ORDER BY order_id
→ Optimizer chọn Layout 2
```

### **2. Predicate Pushdown**

#### **Pushdown là gì?**
> Đẩy filters (WHERE conditions) xuống connector, xử lý ở storage layer

#### **Two-part constraint:**

**Part 1: Domain constraints (ranges + nullability)**
```sql
WHERE age > 18 AND age < 65 AND country IS NOT NULL

Domain:
  age: [19, 64]
  country: non-null
```

**Part 2: Black-box predicate**
```sql
WHERE complex_function(column) > 100

→ Connector không hiểu function này
→ Presto filter sau khi đọc data
```

#### **Ví dụ với Hive/ORC:**
```sql
SELECT * FROM orders 
WHERE order_date = '2026-01-01' AND amount > 100

Pushdown to ORC reader:
  1. Partition pruning: Chỉ đọc partition order_date=2026-01-01
  2. Stripe skipping: Dùng ORC statistics để bỏ qua stripes
  3. Row filtering: Filter amount > 100 khi deserialize
  
→ Giảm data đọc từ HDFS
```

#### **Ví dụ với MySQL (JDBC):**
```sql
SELECT orders.*, customers.name
FROM hive.orders
JOIN mysql.customers ON orders.customer_id = customers.id
WHERE customers.country = 'VN'

Pushdown to MySQL:
  SELECT id, name FROM customers WHERE country = 'VN'
  
→ MySQL filter trước, giảm data transfer về Presto
```

---

## 12. MapReduce vs Presto - So sánh

### **Kiến trúc:**

| Aspect | MapReduce | Presto |
|--------|-----------|--------|
| **Execution Model** | Batch, 2-stage (Map→Reduce) | DAG, multi-stage pipeline |
| **Data Transfer** | Disk-based | Memory-to-memory |
| **Intermediate Results** | Write to HDFS | Keep in memory |
| **Fault Tolerance** | Re-run failed tasks | Query fails if any task fails |

### **Performance:**

```
MapReduce Query Flow:
┌──────────┐
│   Map    │ → [Write to disk] → 
└──────────┘                     ↓
                           ┌──────────┐
                           │  Shuffle │ → [Write to disk] →
                           └──────────┘                    ↓
                                                    ┌──────────┐
                                                    │  Reduce  │
                                                    └──────────┘
Time: Minutes to Hours

Presto Query Flow:
┌──────────┐    ┌──────────┐    ┌──────────┐
│ Stage 1  │ ══>│ Stage 2  │ ══>│ Stage 3  │
└──────────┘    └──────────┘    └──────────┘
     ↓               ↓               ↓
  Memory         Memory          Memory
  
Time: Milliseconds to Minutes
```

### **Use Cases:**

**MapReduce/Hive:**
- ✅ Large-scale ETL
- ✅ Batch processing
- ✅ Fault-tolerant jobs
- ✅ Jobs có thể chạy hàng giờ
- ✅ Dữ liệu không fit in memory

**Presto:**
- ✅ Interactive analytics
- ✅ Ad-hoc queries
- ✅ BI dashboards
- ✅ Developer analytics
- ✅ A/B testing analysis
- ❌ Dữ liệu phải fit in cluster memory

### **Query Example:**

```sql
-- Same SQL syntax!
SELECT country, COUNT(*), AVG(amount)
FROM orders
WHERE order_date >= '2026-01-01'
GROUP BY country
ORDER BY COUNT(*) DESC
LIMIT 10

Hive (MapReduce):
  Time: 2-5 minutes
  Fault tolerance: Cao
  Memory: Không quan trọng

Presto:
  Time: 5-30 seconds
  Fault tolerance: Thấp (query fails if task fails)
  Memory: Critical (query fails if out of memory)
```

---

## 13. Query Execution - In-Memory Processing

### **All tasks run in parallel:**

```
Stage 1 (Table Scan):
  Worker 1: Task 1.0 ┐
  Worker 2: Task 1.1 ├─ All run at same time
  Worker 3: Task 1.2 ┘

Stage 2 (Aggregation):
  Worker 1: Task 2.0 ┐
  Worker 2: Task 2.1 ├─ All run at same time
  Worker 3: Task 2.2 ┘
```

### **No wait time between stages (pipelined):**

```
Timeline:
0s   ─ Stage 1 starts reading
0.1s ─ Stage 1 produces first batch → Stage 2 starts processing
0.2s ─ Stage 1 produces second batch → Stage 2 processes
...

❌ NOT like this (MapReduce):
0s   ─ Map phase (100% complete)
60s  ─ Shuffle phase (100% complete)
120s ─ Reduce phase starts

✅ Presto (pipelined):
0s   ─ All stages start, data flows through pipeline
```

### **If one task fails, ALL tasks fail:**

```
Worker 1: Task OK
Worker 2: Task OK
Worker 3: Task FAILED (out of memory)

Result:
  → Entire query FAILS
  → All workers stop their tasks
  → Client receives error
  
⚠️ Presto không retry tasks!
   (Khác với MapReduce có retry)
```

### **Memory-to-memory transfer:**

```
Worker 1 (produces data):
  ┌─────────────┐
  │ Memory Buffer│ ──HTTP──> Worker 2 (consumes data)
  └─────────────┘             ┌─────────────┐
                              │ Memory Buffer│
                              └─────────────┘

❌ NO disk I/O for intermediate data
✅ Streaming over network
```

### **If aggregated data doesn't fit in memory:**

```sql
SELECT user_id, COUNT(*)
FROM huge_table  -- 10 billion rows, 1 billion distinct users
GROUP BY user_id

In-memory hash table for GROUP BY:
  {
    user_1: count_1,
    user_2: count_2,
    ...
    user_1000000000: count_1000000000  ← Too many keys!
  }

Result:
  → Worker runs out of memory
  → Query FAILS with "Query exceeded per-node memory limit"
  → Entire query dies
  
Solution:
  - Increase worker memory
  - Use approximate aggregations (approx_distinct)
  - Pre-aggregate data in ETL
```

### **Memory management:**

```
Cluster Memory:
  10 workers × 64GB RAM = 640GB total cluster memory
  
Query Memory:
  - Each query gets a slice of memory
  - Coordinator tracks memory usage
  - If query exceeds limit → KILLED
  
Worker doesn't die:
  - Worker process continues running
  - Only the query fails
  - Other concurrent queries unaffected
  - Memory is released and reused
```

---

## 14. Tổng kết - Khi nào dùng Presto?

### **✅ Presto phù hợp khi:**

1. **Interactive analytics**: Cần kết quả nhanh (seconds)
2. **Ad-hoc queries**: Explore dữ liệu, không biết trước query
3. **BI dashboards**: Tableau, Power BI
4. **Federated queries**: JOIN data từ nhiều sources (Hive + MySQL)
5. **Dữ liệu fit in cluster memory**
6. **Có ANSI SQL expertise** trong team

### **❌ Presto KHÔNG phù hợp khi:**

1. **Large-scale ETL**: Dùng Spark/Hive
2. **Dữ liệu quá lớn** không fit memory: Dùng Hive/Spark
3. **Cần fault tolerance cao**: Dùng MapReduce
4. **Batch jobs chạy hàng giờ**: Dùng Hive/Spark
5. **Write-heavy workloads**: Presto là read-only

### **Best Practice: Kết hợp cả hai**

```
Architecture:
1. Hive/Spark: ETL pipeline (hourly/daily)
   → Clean, transform, aggregate data
   → Write to optimized formats (ORC, Parquet)
   → Partition by common filter columns

2. Presto: Interactive queries
   → Query the cleaned data from step 1
   → Fast responses for analysts
   → BI tools connect via JDBC
   
Result: Best of both worlds!
```

---

Hy vọng giải thích chi tiết này giúp bạn hiểu rõ về Presto! Có thắc mắc gì thêm không?